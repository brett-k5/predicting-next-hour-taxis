{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caitlin\\Documents\\Brett_TTT_projects\\predicting_next_hour_taxis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caitlin\\Anaconda3\\envs\\sprint_13_test_env\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Third-party imports\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import gc\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Third-party imports - pmdarima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Third-party imports - statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Local application imports\n",
    "import src.pre_processing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_orders_df = pd.read_csv('taxi.csv', index_col=[0], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_orders = taxi_orders_df = pd.read_csv('taxi.csv', index_col=[0], parse_dates=[0])\n",
    "hourly_orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del taxi_orders_df\n",
    "del pre.taxi_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_orders.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hourly_orders.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(hourly_orders)\n",
    "print(f\"ADF Statistic: {result[0]}\")\n",
    "print(f\"p-value: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A p-value of .03 means that we can reject the null hypothesis that our data has a unit root (and therefore lacks stationarity). This means that no differencing is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(hourly_orders, model='additive', period=24)\n",
    "fig = decomposition.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, our data exhibits a mild trend toward increased taxi use which likely results from increasingly nice weather. The the smymetrical data with regular fluctions between periods suggests seasonality as well. Let's get a closer look to confirm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_week = hourly_orders['2018-03-01': '2018-03-14']\n",
    "one_week.plot(title='Two weeks of Orders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "As we suspected from our plot of the full data set, the above plot confirms that our data exhibits daily seasonality. It also suggests there may be some mild weekly seasonality (see for example 02-05 and 09-12). Therefore, we will add some lag features to pick up on these patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hourly_orders \n",
    "del pre.hourly_orders\n",
    "del pre.train_hour\n",
    "del pre.test_hour\n",
    "del pre.train_12_hours\n",
    "del pre.test_12_hours\n",
    "del pre.train_day\n",
    "del pre.test_day\n",
    "del pre.train_3_days\n",
    "del pre.test_3_days\n",
    "del pre.train_week\n",
    "del pre.test_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first plot of the data showed daily seasonality, and since the unit of time we are interested in predicting value for is hours we will define one season as being 24 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pacf_acf(s: int, target_train: pd.Series, forecast_length: str) -> None:\n",
    "\n",
    "    # Plot PACF for up to 7 seasonal cycles (7 * s lags)\n",
    "    max_lag = 31 * s\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12,8))\n",
    "\n",
    "    # PACF plot\n",
    "    plot_pacf(pre.y_train_hour, lags=max_lag, ax=ax[0])\n",
    "    ax[0].set_title(f'{forecast_length} Forecast Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "    # ACF plot (useful for seasonal MA terms)\n",
    "    plot_acf(target_train, lags=max_lag, ax=ax[1])\n",
    "    ax[1].set_title(f'{forecast_length} Forecast Autocorrelation Function (ACF)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_acf(24, pre.y_train_hour, 'Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though y_train_hour and y_train_12_hours are the same data, we include y_train_12_hours here to align with the rest of the pipeline. This way if someone decides to make a change to y_train_12_hours, no further changes will need to be made to the code in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacf_acf(24, pre.y_train_12_hours, '12 Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf_acf(24, pre.y_train_day, 'Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacf_acf(24, pre.y_train_3_days, '3 Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacf_acf(24, pre.y_train_week, 'Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we are working with nearly identical training sets (differing only in how much was left from the full set when the test set was taken out), it was a little bit of a formality to plot ACF and PACF plots for each training set. However, while it would have been unexpected to find differences between the training set targets, any differences that were there would have been worth knowing about. Nevertheless, as you can see there is almost no difference between the plots from the respective data sets. Both the PACF and ACF plots show big spikes at 24 hour intervals, reflecting the data's strong daily seasonality. \n",
    "\n",
    "The seven spikes above the confidence intervals in our PACF plot suggest that we should try a p value of 7. In fact, the plot suggests that we could try more, but we don't want our model to take forever to fit. There do not appear to be any siginficant drop offs in our ACF plot, which suggests a q value of 0 is appropriate. That is, we will not make a moving average adjustment on the order level. Our adfuller test suggested that our data did not have any trend. However, our decomposed plot seems to show a mild upward trend in taxi usage, and there is a tiny downward trend in the ACF plots which reflects a mild decrease in correlation between lag values near the present and lag values from the distant past. This suggests a value of 1 for d might be appropriate. The seasonal peaks in the PACF plot suggest a P value as high as 7 would be appropriate. However, after the first seasonaly period of 24 hours, the plot doesn't reach that peak again until 168 hours. For the sake of time and computational efficiency, therefore, we will set P to 1. There are no signifcant spikes or drops at seasonal intervals on the PACF plot so we can likely keep D and Q at zero. As we have already discussed, we are working with daily seasonality, so we will set m to 24. The hyperparameters for thos SARIMA model are set in models.py in the src folder. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
